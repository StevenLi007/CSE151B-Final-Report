{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc36a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in ./.local/lib/python3.9/site-packages (1.7.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "!pip install --user xgboost\n",
    "import xgboost\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbcd94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216a4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df = pd.read_csv('metaData_taxistandsID_name_GPSlocation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41a9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "    return dt.year, dt.month, dt.day, dt.hour, dt.weekday()\n",
    "\n",
    "def polyline_to_trip_duration(polyline):\n",
    "    return max(polyline.count(\"[\") - 1, 0) * 15\n",
    "\n",
    "import ast\n",
    "def parse_stand(df):\n",
    "    def extract_coordinate(polyline):\n",
    "        coordinate = ast.literal_eval(polyline)[0]\n",
    "        return float(coordinate[0]), float(coordinate[1])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        origin_stand = row['ORIGIN_STAND']\n",
    "        if 'POLYLINE' not in row.index:\n",
    "            if origin_stand == -100:\n",
    "                continue\n",
    "            else:\n",
    "                origin = origin_stand\n",
    "                area = origin_df.iloc[int(origin) - 1, 1]\n",
    "                int1, int2 = origin_df.iloc[int(origin) - 1, 2:4]\n",
    "                if int1 == '41.163066654-8.67598304213':\n",
    "                    int1, int2 = '41.163066654', '-8.67598304213'\n",
    "                df.at[index, 'Latitude'] = float(int1)\n",
    "                df.at[index, 'Longitude'] = float(int2) \n",
    "                continue\n",
    "                \n",
    "        \n",
    "        polyline = row['POLYLINE']\n",
    "        \n",
    "        if origin_stand == -100:\n",
    "            if polyline:\n",
    "                latitude, longitude = extract_coordinate(polyline)\n",
    "                df.at[index, 'Latitude'] = latitude\n",
    "                df.at[index, 'Longitude'] = longitude\n",
    "        else:\n",
    "            origin = origin_stand\n",
    "            area = origin_df.iloc[int(origin) - 1, 1]\n",
    "            int1, int2 = origin_df.iloc[int(origin) - 1, 2:4]\n",
    "            if int1 == '41.163066654-8.67598304213':\n",
    "                int1, int2 = '41.163066654', '-8.67598304213'\n",
    "            df.at[index, 'Latitude'] = float(int1)\n",
    "            df.at[index, 'Longitude'] = float(int2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8521eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = [(0, 360, 0.4, 200), (360, 900, 0.4, 200), (900, 1500,0.01, 200), (1500, 2000, 0.01, 200)]\n",
    "\n",
    "dictOne, dictTwo, dictThree, dictFour, dictFive, dictSix = {}, {}, {}, {}, {}, {}\n",
    "index = 0\n",
    "\n",
    "for idx, (lower, upper, lr, offset) in enumerate(bins):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    filename = 'model' + str(idx)\n",
    "    file_extension = 'model'\n",
    "    file_path = f\"{filename}.{file_extension}\"\n",
    "    model.load_model(file_path)\n",
    "\n",
    "    # testing predictions\n",
    "    modelOut = pd.read_csv('680_score.csv')\n",
    "    newdf =  modelOut[(modelOut.get(\"TRAVEL_TIME\") > lower - offset) & (modelOut.get(\"TRAVEL_TIME\") <= upper + offset)]\n",
    "    \n",
    "    test_df = pd.read_csv('test_public.csv')\n",
    "    mergedUnderDf = test_df.merge(newdf, left_on='TRIP_ID', right_on='TRIP_ID')\n",
    "    test_df = mergedUnderDf\n",
    "    \n",
    "    test_df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = test_df[[\"TIMESTAMP\"]].apply(parse_time, axis=1, result_type=\"expand\")\n",
    "    \n",
    "    test_df['ORIGIN_STAND'].fillna(-100.0, inplace=True)\n",
    "    test_df = parse_stand(test_df)\n",
    "    test_df['TAXI_ID'] = test_df['TAXI_ID'] - 20000000 \n",
    "    # perform one-hot encoding\n",
    "    one_hot = pd.get_dummies(test_df['CALL_TYPE'])\n",
    "    # concatenate the one-hot encoded dataframe with the original dataframe\n",
    "    test_df['A'] = 0\n",
    "    test_df['B'] = 0\n",
    "    test_df['C'] = 0\n",
    "    \n",
    "    if('A' in one_hot.columns):\n",
    "        test_df['A'] = one_hot['A']\n",
    "    if('B' in one_hot.columns):\n",
    "        test_df['B'] = one_hot['B']\n",
    "    if('C' in one_hot.columns):\n",
    "        test_df['C'] = one_hot['C']\n",
    "\n",
    "    tripidSeriesUnder = test_df.get('TRIP_ID')\n",
    "\n",
    "    # Define a list of columns to be scaled\n",
    "    columns_to_scale = [\"TAXI_ID\", \"YR\", \"MON\", \"DAY\", \"HR\", \"WK\", \"A\", \"B\", \"C\", \"Latitude\", \"Longitude\"]\n",
    "\n",
    "    X_test = test_df.drop([\"CALL_TYPE\",'ORIGIN_CALL', 'DAY_TYPE', 'TRIP_ID', \"TIMESTAMP\", \"ORIGIN_STAND\", \"MISSING_DATA\", \"TRAVEL_TIME\"], axis=1)\n",
    "    X_test_scaled = X_test.copy()\n",
    "    # Create a scaler object and fit it on the training data\n",
    "    scaler.fit(test_df[columns_to_scale])\n",
    "    X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "    X_test_scaled_converted = xgb.DMatrix(X_test_scaled)\n",
    "    y_pred_under = model.predict(X_test_scaled_converted)\n",
    "\n",
    "\n",
    "    for i, val in enumerate(tripidSeriesUnder.values):\n",
    "        if(index == 0):\n",
    "            dictOne[val] = y_pred_under[i]\n",
    "        elif(index == 1):\n",
    "            dictTwo[val] = y_pred_under[i]\n",
    "        elif(index == 2):\n",
    "            dictThree[val] = y_pred_under[i]\n",
    "        elif(index == 3):\n",
    "            dictFour[val] = y_pred_under[i]\n",
    "        elif(index == 4):\n",
    "            dictFive[val] = y_pred_under[i]\n",
    "        else:\n",
    "            dictSix[val] = y_pred_under[i]\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05f80a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1       505.035583\n",
      "T2       393.028679\n",
      "T3       863.954803\n",
      "T4       695.635620\n",
      "T5      1708.607300\n",
      "           ...     \n",
      "T323     603.716812\n",
      "T324     870.590576\n",
      "T325     406.813675\n",
      "T326     404.697815\n",
      "T327     593.048233\n",
      "Length: 320, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Combine the dictionaries and average values for duplicate keys\n",
    "combined_dict = {}\n",
    "all_dicts = [dictOne, dictTwo, dictThree, dictFour, dictFive, dictSix]\n",
    "\n",
    "for dictionary in all_dicts:\n",
    "    for key, value in dictionary.items():\n",
    "        if key in combined_dict:\n",
    "            combined_dict[key].append(value)\n",
    "        else:\n",
    "            combined_dict[key] = [value]\n",
    "\n",
    "for key, values in combined_dict.items():\n",
    "    average_value = sum(values) / len(values)\n",
    "    combined_dict[key] = average_value\n",
    "\n",
    "# Extract the numeric part from the keys and sort based on numeric value\n",
    "sorted_keys = sorted(combined_dict.keys(), key=lambda x: int(x[1:]))\n",
    "\n",
    "# Create a pandas Series with the sorted keys and values\n",
    "s = pd.Series([combined_dict[k] for k in sorted_keys], index=sorted_keys)\n",
    "\n",
    "print(s)\n",
    "\n",
    "# Creating the DataFrame\n",
    "data = {\n",
    "    'TRIP_ID': s.index,\n",
    "    'TRAVEL_TIME': s.values\n",
    "}\n",
    "submit_df = pd.DataFrame(data)\n",
    "\n",
    "# Saving the DataFrame as a CSV file\n",
    "submit_df.to_csv('myPreds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
